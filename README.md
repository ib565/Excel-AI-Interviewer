# Excel Interviewer AI

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-red.svg)](https://streamlit.io/)
[![Gemini AI](https://img.shields.io/badge/Gemini-AI-orange.svg)](https://ai.google.dev/)

An AI-powered conversational interviewer that assesses Excel proficiency through structured technical interviews. Built as a proof-of-concept to demonstrate scalable, automated technical skill evaluation.

## ğŸ¯ Problem Statement

Traditional Excel technical interviews are:
- **Time-intensive**: Senior analysts spend 2-3 hours per candidate
- **Inconsistent**: Different interviewers apply varying evaluation standards
- **Scalable bottleneck**: Manual process limits hiring velocity
- **Quality vs. speed trade-off**: Pressure compromises thorough assessment

## ğŸš€ Solution Overview

This AI-driven system conducts structured Excel interviews through natural conversation, evaluates responses in real-time using LLM-powered assessment, and generates comprehensive performance reports.

### Key Features

- **ğŸ¤– Conversational AI Interviewer**: Natural dialogue that adapts to candidate responses
- **ğŸ“Š Intelligent Evaluation**: Structured rubric-based assessment with confidence scoring
- **ğŸ”„ Adaptive Difficulty**: Questions scale based on demonstrated proficiency
- **ğŸ“ˆ Performance Analytics**: Detailed feedback reports with specific improvement recommendations
- **ğŸ”§ Modular Architecture**: Pluggable AI adapters supporting multiple LLM providers
- **ğŸ’¾ Local Persistence**: Complete transcript storage with metadata preservation

## ğŸ—ï¸ Architecture

### System Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Streamlit UI  â”‚â”€â”€â”€â”€â”‚   Core Bridge   â”‚â”€â”€â”€â”€â”‚   AI Adapter    â”‚
â”‚                 â”‚    â”‚  (Protocol)     â”‚    â”‚  (Gemini/Claude)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Session State  â”‚    â”‚   Data Models   â”‚    â”‚   Prompts       â”‚
â”‚  Management     â”‚    â”‚   (Pydantic)    â”‚    â”‚   & Evaluation  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Transcripts   â”‚    â”‚ Question Bank   â”‚    â”‚   Config        â”‚
â”‚   (JSONL)       â”‚    â”‚   (JSON)        â”‚    â”‚   & Logging     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Core Components

#### ğŸ¨ User Interface (Streamlit)
- Clean, professional chat interface
- Real-time conversation display
- Session controls and transcript download
- Performance summary visualization

#### ğŸ”Œ AI Adapter System
- **Protocol-based design** for easy provider switching
- **Function calling** for structured question retrieval
- **Structured outputs** for consistent evaluation
- **Fallback mechanisms** for error handling

#### ğŸ“š Question Bank Management
- **Curated questions** covering core Excel competencies
- **Dynamic generation** using LLM when bank is exhausted
- **Duplicate prevention** within interview sessions
- **Metadata tagging** by capability and difficulty

#### ğŸ’½ Storage Layer
- **JSONL transcripts** for efficient streaming writes
- **Session-based organization** with full metadata
- **Event logging** for analytics and debugging
- **Local persistence** for offline operation

## ğŸ› ï¸ Technology Stack

| Component | Technology | Purpose |
|-----------|------------|---------|
| **Frontend** | Streamlit | Web UI and session management |
| **AI Engine** | Google Gemini | Conversational AI and evaluation |
| **Backend** | Python 3.8+ | Core application logic |
| **Data Models** | Pydantic | Type-safe data structures |
| **Storage** | JSON/JSONL | Local data persistence |
| **Configuration** | Python-dotenv | Environment management |

### Design Decisions

- **Adapter Pattern**: Enables easy swapping between AI providers (Gemini, OpenAI, Claude)
- **Protocol-Based Architecture**: Ensures interface consistency across implementations
- **Local-First Storage**: Simplifies deployment and enables offline operation
- **Streaming Transcripts**: JSONL format for efficient append operations

## ğŸ“‹ Prerequisites

- Python 3.8 or higher
- Google Gemini API key
- Virtual environment (recommended)

## ğŸš€ Quick Start

### 1. Clone and Setup

```bash
git clone <repository-url>
cd ExcelInterviewerAI
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### 2. Environment Configuration

Create a `.env` file in the project root:

```env
GEMINI_API_KEY=your_gemini_api_key_here
MODEL=gemini-1.5-flash  # or gemini-1.5-pro
```

### 3. Run the Application

```bash
streamlit run main.py
```

The application will be available at `http://localhost:8501`

## ğŸ¯ Usage

### Interview Flow

1. **Self-Assessment**: Candidates start by describing their Excel experience
2. **Question Selection**: AI chooses appropriate questions from the bank or generates new ones
3. **Conversational Assessment**: Natural dialogue with follow-up questions based on responses
4. **Real-time Evaluation**: LLM evaluates answers using structured rubrics
5. **Performance Summary**: Comprehensive feedback report at interview conclusion

### Question Categories

The system covers core Excel competencies:

- **ğŸ“Š Formulas & Functions**: Cell references, array formulas, advanced functions
- **ğŸ“ˆ Data Analysis**: Pivot tables, data cleaning, analysis tools
- **ğŸ“‰ Visualization**: Charts, conditional formatting, dashboards
- **âš¡ Automation**: Macros, Power Query, data connections
- **ğŸ”§ Advanced Features**: Power Pivot, VBA concepts, external integrations

## ğŸ“Š Evaluation Framework

### Scoring Methodology

- **Defined Criteria**: Fixed criteria for each question
- **Confidence Assessment**: AI self-evaluation of assessment certainty
- **Follow-up Logic**: Clarifying questions when confidence is low
- **Bias Mitigation**: Standardized criteria reduce subjective variance

### Performance Report

Generated reports include:
- **Overall Proficiency Level**: Beginner â†’ Expert classification based on the fixed criteria
- **Strength Analysis**: Areas of demonstrated competence
- **Improvement Areas**: Specific skills needing development
- **Technical Accuracy**: Detailed evaluation of responses
- **Communication Assessment**: Clarity and problem-solving approach

## ğŸ”§ Configuration

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `GEMINI_API_KEY` | Google Gemini API key | Required |
| `MODEL` | Gemini model version | `gemini-2.5-flash` |

### Question Bank

Located at `data/question_bank.json`, contains:
- Curated Excel interview questions
- Evaluation criteria for each question
- Capability and difficulty metadata
- Expansion through LLM generation

## ğŸ“ Project Structure

```
ExcelInterviewerAI/
â”œâ”€â”€ main.py                 # Streamlit application entry point
â”œâ”€â”€ config.py              # Configuration and path management
â”œâ”€â”€ core/                  # Core business logic
â”‚   â”œâ”€â”€ bridge.py         # AI adapter protocol and loading
â”‚   â”œâ”€â”€ models.py         # Pydantic data models
â”‚   â””â”€â”€ utils.py          # Utility functions
â”œâ”€â”€ ai/                    # AI-specific components
â”‚   â”œâ”€â”€ adapter.py        # Gemini AI adapter implementation
â”‚   â””â”€â”€ prompts.py        # LLM prompt templates
â”œâ”€â”€ storage/               # Data persistence layer
â”‚   â”œâ”€â”€ question_bank.py  # Question bank management
â”‚   â””â”€â”€ transcripts.py    # Transcript storage
â”œâ”€â”€ data/                  # Static data files
â”‚   â””â”€â”€ question_bank.json # Question database
â”œâ”€â”€ logs/                  # Application logs
â”œâ”€â”€ transcripts/           # Interview transcripts
â”œâ”€â”€ DESIGN_DOCUMENT.md     # Technical design document
â””â”€â”€ README.md             # This file
```

## ğŸ” Key Design Patterns

### Adapter Protocol
```python
class AIAdapter(Protocol):
    @property
    def name(self) -> str: ...
    def generate_reply(self, messages: List[Message], state: Optional[Dict]) -> AIResponseWrapped: ...
    def generate_performance_summary(self, messages: List[Message]) -> str: ...
```

### Structured Evaluation
```python
class Evaluation(BaseModel):
    question_id: str
    criteria_scores: Dict[str, int]  # 0-5 scale per criterion
    total_score: float
    confidence: float  # 0-1 scale
    feedback: str
```
